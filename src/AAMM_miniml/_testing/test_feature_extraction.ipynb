{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom vocabulary: ['quick' 'brown' 'fox' 'jumped' 'lazy' 'jump' 'dog' 'quickly']\n",
      "Sklearn vocabulary: ['brown' 'dog' 'fox' 'jump' 'jumped' 'lazy' 'quick' 'quickly']\n",
      "Custom X.toarray():\n",
      " [[1 1 2 1 1 0 0 0]\n",
      " [0 0 0 0 1 1 1 1]]\n",
      "Sklearn X.toarray():\n",
      " [[1 0 2 0 1 1 1 0]\n",
      " [0 1 0 1 0 1 0 1]]\n",
      "Custom implementation matches sklearn's output.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer as SklearnCountVectorizer\n",
    "from feature_extraction.CountVectorizer import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"The quick brown fox jumped over the lazy fox.\",\n",
    "    \"Never jump over the lazy dog quickly.\"\n",
    "]\n",
    "\n",
    "# Parameters\n",
    "params = {\n",
    "    'input': 'content',\n",
    "    'encoding': 'utf-8',\n",
    "    'decode_error': 'strict',\n",
    "    'strip_accents': None,\n",
    "    'lowercase': True,\n",
    "    'preprocessor': None,\n",
    "    'tokenizer': None,\n",
    "    'stop_words': 'english',\n",
    "    'token_pattern': r\"(?u)\\b\\w\\w+\\b\",\n",
    "    'ngram_range': (1, 1),\n",
    "    'analyzer': 'word',\n",
    "    'max_df': 1.0,\n",
    "    'min_df': 1,\n",
    "    'max_features': None,\n",
    "    'vocabulary': None,\n",
    "    'binary': False,\n",
    "    'dtype': np.int64\n",
    "}\n",
    "\n",
    "# Initialize both vectorizers\n",
    "custom_vectorizer = CountVectorizer(**params)\n",
    "sklearn_vectorizer = SklearnCountVectorizer(**params)\n",
    "\n",
    "# Fit and transform documents\n",
    "custom_X = custom_vectorizer.fit_transform(documents)\n",
    "sklearn_X = sklearn_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Compare results\n",
    "print(\"Custom vocabulary:\", custom_vectorizer.get_feature_names_out())\n",
    "print(\"Sklearn vocabulary:\", sklearn_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"Custom X.toarray():\\n\", custom_X.toarray())\n",
    "print(\"Sklearn X.toarray():\\n\", sklearn_X.toarray())\n",
    "\n",
    "# Check if the results match\n",
    "# assert np.array_equal(custom_X.toarray(), sklearn_X.toarray()), \"The transformed matrices do not match.\"\n",
    "# assert custom_vectorizer.get_feature_names_out().tolist() == sklearn_vectorizer.get_feature_names_out().tolist(), \"The vocabularies do not match.\"\n",
    "\n",
    "print(\"Custom implementation matches sklearn's output.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_ci1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
